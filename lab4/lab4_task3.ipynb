{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8733968b-2fb1-423b-aa63-04b9f39c6b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "dataset = [\n",
    "    (\"the quick brown fox jumps over the lazy dog\", 0),\n",
    "    (\"some people prefer dogs to cats\", 0),\n",
    "    (\"cats are often more independent than dogs\", 1),\n",
    "    (\"my cat is quite cuddly\", 1),\n",
    "    (\"dogs are often considered man's best friend\", 0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d320aad6-7d9e-4d7b-8452-73e659905ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [sequence for sequence, label in dataset]\n",
    "labels = np.array([label for sequence, label in dataset])\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c130a73c-c896-41f1-abcf-053bff1262f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "input_ids = [tokenizer.encode(sequence, add_special_tokens=True) for sequence in sequences]\n",
    "max_length = max(len(sequence) for sequence in input_ids)\n",
    "input_ids = [sequence + [0] * (max_length - len(sequence)) for sequence in input_ids]\n",
    "input_ids = np.array(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab8ac3cc-5295-4eda-b3cc-aea14ec401fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(input_ids, labels, batch_size=32, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_ids, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(input_ids.shape[0])\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ca423e-1191-45ba-91e6-512f8099f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.7425371408462524, accuracy = 0.20000000298023224\n",
      "Epoch 2: loss = 0.6634699106216431, accuracy = 0.4000000059604645\n",
      "Epoch 3: loss = 0.6946564316749573, accuracy = 0.46666666865348816\n",
      "Epoch 4: loss = 0.6545277833938599, accuracy = 0.5\n",
      "Epoch 5: loss = 0.6586092710494995, accuracy = 0.5600000023841858\n",
      "Epoch 6: loss = 0.6782515048980713, accuracy = 0.6000000238418579\n",
      "Epoch 7: loss = 0.6282340884208679, accuracy = 0.6571428775787354\n",
      "Epoch 8: loss = 0.6625038981437683, accuracy = 0.6499999761581421\n",
      "Epoch 9: loss = 0.6406915783882141, accuracy = 0.644444465637207\n",
      "Epoch 10: loss = 0.6326515674591064, accuracy = 0.6399999856948853\n",
      "Epoch 11: loss = 0.5980828404426575, accuracy = 0.6727272868156433\n",
      "Epoch 12: loss = 0.5878999829292297, accuracy = 0.699999988079071\n",
      "Epoch 13: loss = 0.584142804145813, accuracy = 0.7230769395828247\n",
      "Epoch 14: loss = 0.5384200811386108, accuracy = 0.7428571581840515\n",
      "Epoch 15: loss = 0.5261024236679077, accuracy = 0.7599999904632568\n",
      "Epoch 16: loss = 0.5620728731155396, accuracy = 0.7749999761581421\n",
      "Epoch 17: loss = 0.5111234784126282, accuracy = 0.7882353067398071\n",
      "Epoch 18: loss = 0.4694904386997223, accuracy = 0.800000011920929\n",
      "Epoch 19: loss = 0.4532298445701599, accuracy = 0.8105263113975525\n",
      "Epoch 20: loss = 0.42325130105018616, accuracy = 0.8199999928474426\n",
      "Epoch 21: loss = 0.3928309679031372, accuracy = 0.8285714387893677\n",
      "Epoch 22: loss = 0.4006434381008148, accuracy = 0.8363636136054993\n",
      "Epoch 23: loss = 0.37222230434417725, accuracy = 0.843478262424469\n",
      "Epoch 24: loss = 0.3078576922416687, accuracy = 0.8500000238418579\n",
      "Epoch 25: loss = 0.35816359519958496, accuracy = 0.8560000061988831\n",
      "Epoch 26: loss = 0.31612104177474976, accuracy = 0.8615384697914124\n",
      "Epoch 27: loss = 0.304542601108551, accuracy = 0.8666666746139526\n",
      "Epoch 28: loss = 0.2344704568386078, accuracy = 0.8714285492897034\n",
      "Epoch 29: loss = 0.3017577826976776, accuracy = 0.8758620619773865\n",
      "Epoch 30: loss = 0.278633177280426, accuracy = 0.8799999952316284\n",
      "Epoch 31: loss = 0.22647246718406677, accuracy = 0.8838709592819214\n",
      "Epoch 32: loss = 0.22425028681755066, accuracy = 0.887499988079071\n",
      "Epoch 33: loss = 0.25034022331237793, accuracy = 0.8909090757369995\n",
      "Epoch 34: loss = 0.19854305684566498, accuracy = 0.8941176533699036\n",
      "Epoch 35: loss = 0.1897358000278473, accuracy = 0.8971428275108337\n",
      "Epoch 36: loss = 0.17538830637931824, accuracy = 0.8999999761581421\n",
      "Epoch 37: loss = 0.19494399428367615, accuracy = 0.9027026891708374\n",
      "Epoch 38: loss = 0.15510502457618713, accuracy = 0.9052631855010986\n",
      "Epoch 39: loss = 0.16055384278297424, accuracy = 0.9076923131942749\n",
      "Epoch 40: loss = 0.14805302023887634, accuracy = 0.9100000262260437\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "dataset = create_dataset(input_ids, labels)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "accuracy_object = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "def train_step(input_ids, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_ids, training=True)[0]\n",
    "        loss_value = loss_object(labels, logits)\n",
    "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_accuracy(labels, logits)\n",
    "    return loss_value, train_accuracy.result()\n",
    "\n",
    "for epoch in range(40):\n",
    "    for input_ids, labels in dataset:\n",
    "        loss_value, accuracy = train_step(input_ids, labels)\n",
    "    print(f'Epoch {epoch + 1}: loss = {loss_value}, accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80a47a3-e183-4a0e-9556-5a4e0171c998",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLosses\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf47de-52df-49f6-bbf1-2f15c3d5b9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
